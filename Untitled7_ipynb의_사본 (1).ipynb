{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lizZPUGSgiP5",
        "outputId": "bb8b8ae2-0d17-4ba4-f612-4d826d35539e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jbg3uDeugSzH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "956bd83f-ef5f-4d44-ffef-02dfb0773e29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\nprint(df.isnull())\\ndf.dropna(inplace=True)\\nprint(df)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Winter/Public.csv', low_memory=False,encoding='utf-8') ### 데이터셋 불러오기\n",
        "df = df.iloc[:, [4,6]] ### 분류번호와 제목만 가져옵니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(subset = ['title'], inplace=True)  #제목에 겹치는게 많아 이럴 경우 중복 데이터를 삭제합니다.\n",
        "\n",
        "df['title'] = df['title'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\") #영어 분류는 제외하기로 하였기에 영어를 공백으로 제거\n",
        "\n",
        "df['title'] = df['title'].str.replace('^ +', \"\")#공백과 띄어쓰기만 있는 셀들을 확인\n",
        "\n",
        "df['class_no']= df['class_no'].str.replace(\"[^0-9]\", \"\") #라벨지에 가끔 숫자 대신 글자가 들어가 있는 경우를 확인 이를 제거\n",
        "\n",
        "df['class_no'] = df['class_no'].str.replace('^ +', \"\")#공백과 띄어쓰기만 있는 셀들을 확인\n",
        "\n",
        "df.replace('', np.nan, inplace=True)#이를 drop하기 위하여 None으로 변경합니다.\n",
        "\n",
        "df = df.dropna(how = 'any') #none은 전부 드랍\n",
        "\n",
        "df = df.reset_index(drop = True) #이 경우 셀들의 배열이 맞지않아 배열을 다시 하여 줍니다.\n",
        "\n",
        "X = df.iloc[:, 1] #제목만 따로 분리\n",
        "y = df.iloc[:, 0] #라벨만 따로 분리\n",
        "y = y.str[:1]  #라벨의 앞자리 즉 분류 자리수만 가져와 확인합니다.\n",
        "\n",
        "y = y.astype(float)\n",
        "\n",
        "\n",
        "  \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False, random_state=1004)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmG1BT4AnLSI",
        "outputId": "14d9a5d6-dbf9-4575-bfd7-516d5dbb88d8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train) #X_train을 리스트의 형태로 변경\n",
        "word_to_index = tokenizer.word_index\n",
        "X_train_encoded = tokenizer.texts_to_sequences(X_train)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIM1z-xPj9Td",
        "outputId": "619a6020-4410-48d5-cb8f-222f37c736d5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 2\n",
        "total_cnt = len(word_to_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('제목의 최대 길이 : %d' % max(len(sample) for sample in X_train_encoded))\n",
        "\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합(vocabulary)에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCTrF1enawFU",
        "outputId": "40bbd113-3fba-4ba0-8a51-a12861dbb9a7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "메일의 최대 길이 : 50\n",
            "등장 빈도가 1번 이하인 희귀 단어의 수: 138928\n",
            "단어 집합(vocabulary)에서 희귀 단어의 비율: 63.452799079229216\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 13.247362027305615\n"
          ]
        }
      ]
    }
  ]
}